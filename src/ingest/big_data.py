# src/ingest/big_data.py
import pandas as pd
import numpy as np
import os
from datetime import datetime, timedelta

class BigDataManager:
    def __init__(self, csv_path="data/history_50k.csv"):
        self.csv_path = csv_path
        os.makedirs("data", exist_ok=True)

    def get_combined_data(self, live_df: pd.DataFrame, target_size=50000):
        """
        ØªØ±Ú©ÛŒØ¨ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ ØªØ¶Ù…ÛŒÙ† Ø³Ù„Ø§Ù…Øª Ø¯Ø§Ø¯Ù‡.
        """
        # 1. ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ø¯ÛŒØªØ§ÛŒ Ø²Ù†Ø¯Ù‡
        live_df = self._clean_dataframe(live_df)

        # 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡
        historical_df = self._load_history()
        historical_df = self._clean_dataframe(historical_df)

        # 3. ØªØ±Ú©ÛŒØ¨ (Concat)
        if not historical_df.empty and not live_df.empty:
            combined_df = pd.concat([historical_df, live_df])
        elif not historical_df.empty:
            combined_df = historical_df
        else:
            combined_df = live_df

        # 4. Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
        combined_df = combined_df[~combined_df.index.duplicated(keep='last')]
        combined_df.sort_index(inplace=True)
        
        # 5. --- FIX: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ffill Ø¨Ù‡ Ø¬Ø§ÛŒ interpolate ---
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² interpolate(method='time') Ø¨Ø§Ø¹Ø« Ø§Ø±ÙˆØ± NotImplementedError Ù…ÛŒâ€ŒØ´Ø¯.
        # ffill (Forward Fill) Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ù… Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ø§ Ø¢Ø®Ø±ÛŒÙ† Ù‚ÛŒÙ…Øª Ù…Ø¹ØªØ¨Ø± Ù¾Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø§Ù…Ù†â€ŒØªØ± Ø§Ø³Øª.
        combined_df = combined_df.ffill()
        
        # Ø­Ø°Ù Ù‡Ø±Ú¯ÙˆÙ†Ù‡ NaN Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ (Ù…Ø«Ù„Ø§Ù‹ Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ Ø¯ÛŒØªØ§)
        combined_df.dropna(inplace=True)

        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø³Ø§ÛŒØ² Ù‡Ø¯Ù (Ù…Ø«Ù„Ø§ 50 Ù‡Ø²Ø§Ø± ØªØ§) Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø³Ù†Ú¯ÛŒÙ† Ø´Ø¯Ù†
        if len(combined_df) > target_size:
            combined_df = combined_df.tail(target_size)

        print(f"ğŸ“Š Data Merge Stats: Total={len(combined_df)} candles")
        return combined_df

    def _clean_dataframe(self, df):
        """
        ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ ÙØ±Ù…Øª Ø²Ù…Ø§Ù† Ùˆ Ø­Ø°Ù NaN
        """
        if df is None or df.empty:
            return pd.DataFrame()

        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø²Ù…Ø§Ù† Ø§Ø³Øª
        if not isinstance(df.index, pd.DatetimeIndex):
            try:
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ù‡ datetime
                df.index = pd.to_datetime(df.index)
            except:
                return pd.DataFrame() # Ø§Ú¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù†Ø´Ø¯ØŒ Ø¯ÛŒØªØ§ÛŒ Ø®Ø±Ø§Ø¨ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
        
        # Ø­Ø°Ù ØªØ§ÛŒÙ…â€ŒØ²ÙˆÙ†
        if df.index.tz is not None:
            df.index = df.index.tz_localize(None)

        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¹Ø¯Ø¯ÛŒ Ù‡Ø³ØªÙ†Ø¯ (Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø±ÙˆØ± Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ø§Øª)
        cols = ['open', 'high', 'low', 'close', 'volume']
        for col in cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')

        # Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‚ÛŒÙ…Øª ÛŒØ§ Ø­Ø¬Ù… Ù†Ø¯Ø§Ø±Ù†Ø¯ (NaN Ø´Ø¯Ù†Ø¯)
        df.dropna(subset=['close', 'volume'], inplace=True)
        
        return df

    def _load_history(self):
        if os.path.exists(self.csv_path):
            try:
                # Ø®ÙˆØ§Ù†Ø¯Ù† CSV Ø¨Ø§ Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† ØµØ­ÛŒØ­ Ø§ÛŒÙ†Ø¯Ú©Ø³
                df = pd.read_csv(self.csv_path, index_col=0, parse_dates=True)
                return df
            except Exception as e:
                print(f"âš ï¸ Corrupt CSV: {e}. Starting fresh.")
                # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø®Ø±Ø§Ø¨ Ø¨ÙˆØ¯ Ø­Ø°ÙØ´ Ú©Ù†
                try:
                    os.remove(self.csv_path)
                except: pass
                return pd.DataFrame()
        return pd.DataFrame()