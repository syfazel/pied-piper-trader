# src/ml/tuner.py
import sys
import os

# --- FIX: Ø§ÙØ²ÙˆØ¯Ù† Ø±ÛŒØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ Ù…Ø³ÛŒØ± Ù¾Ø§ÛŒØªÙˆÙ† ---
# Ø§ÛŒÙ† Ø®Ø· Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ù¾Ø§ÛŒØªÙˆÙ† Ù¾ÙˆØ´Ù‡ Ø§ØµÙ„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ø¯
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))

import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from sklearn.ensemble import GradientBoostingClassifier

# Ø§Ú©Ù†ÙˆÙ† Ø§ÛŒÙ…Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ Ø¨Ø¯ÙˆÙ† Ø®Ø·Ø§ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
from src.ingest.big_data import BigDataManager
from src.features.indicators import TechnicalFeatures
from src.ml.dataset import DataLabeler

def run_tuning():
    print("ğŸ§ª Starting Hyperparameter Tuning (Optimization)...")
    
    # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    mgr = BigDataManager()
    # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø¯ÛŒØªØ§ Ù†Ø¨ÙˆØ¯ØŒ Ø§Ø±ÙˆØ± Ù†Ø¯Ù‡ØŒ Ø¨Ù„Ú©Ù‡ ØªÙ„Ø§Ø´ Ú©Ù† Ø¨Ø³Ø§Ø²ÛŒ ÛŒØ§ Ù„ÙˆØ¯ Ú©Ù†ÛŒ
    if not os.path.exists("data/history_50k.csv"):
        print("âŒ Data file not found. Please run the main app first to generate data.")
        return

    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù„ Ø¯ÛŒØªØ§ Ø¨Ø±Ø§ÛŒ ØªÛŒÙˆÙ†ÛŒÙ†Ú¯
    print("ğŸ“‚ Loading 50k dataset...")
    df = pd.read_csv("data/history_50k.csv", index_col=0, parse_dates=True)
    print(f"   Data loaded: {len(df)} rows")
    
    # 2. Ù¾Ø±Ø¯Ø§Ø²Ø´
    print("âš™ï¸ Calculating Indicators...")
    df = TechnicalFeatures.add_all(df)
    
    print("ğŸ·ï¸ Labeling & Scaling...")
    labeler = DataLabeler()
    # ØªÙˆØ¬Ù‡: Ø§ÛŒÙ†Ø¬Ø§ ÙÙ‚Ø· Ø¨Ù‡ X Ùˆ y Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ…ØŒ Scaler Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
    X, y, _ = labeler.prepare(df)
    
    # 3. ØªØ¹Ø±ÛŒÙ ÙØ¶Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ (Grid)
    param_dist = {
        'n_estimators': [200, 400, 600, 800],
        'learning_rate': [0.01, 0.03, 0.05, 0.1],
        'max_depth': [3, 4, 5, 6],
        'min_samples_split': [10, 20, 50],
        'subsample': [0.8, 0.9, 1.0]
    }
    
    # 4. Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡
    model = GradientBoostingClassifier(random_state=42)
    
    # 5. Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØµØ§Ø¯ÙÛŒ (Random Search)
    tscv = TimeSeriesSplit(n_splits=3)
    
    search = RandomizedSearchCV(
        estimator=model,
        param_distributions=param_dist,
        n_iter=10, # ØªØ¹Ø¯Ø§Ø¯ ØªØ³Øªâ€ŒÙ‡Ø§ (Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨ÛŒØ´ØªØ± Ú©Ù†ÛŒØ¯ØŒ Ù…Ø«Ù„Ø§ 20)
        scoring='precision', 
        cv=tscv,
        verbose=1,
        n_jobs=-1
    )
    
    print("ğŸš€ Tuning in progress... (This may take a few minutes)")
    search.fit(X, y)
    
    print("\nâœ… Optimization Complete!")
    print(f"ğŸ† Best Precision Score: {search.best_score_:.2%}")
    print("ğŸ† Best Parameters:")
    print(search.best_params_)
    
    return search.best_params_

if __name__ == "__main__":
    run_tuning()