# src/ml/ensemble.py
from sklearn.linear_model import LogisticRegression
from src.ml.model import MarketPredictor
from src.ml.lstm_model import LSTM_Predictor
from src.ml.dataset import DataLabeler
import pandas as pd
import numpy as np

class EnsemblePredictor:
    def __init__(self):
        self.predictor_A = None 
        self.predictor_B = LogisticRegression(random_state=42, solver='liblinear')
        self.aux_predictor = MarketPredictor() 
        self.is_trained = False

    def train_all(self, X: pd.DataFrame, y: pd.Series):
        """Ø¢Ù…ÙˆØ²Ø´ ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        
        # 1. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ LSTM
        X_seq, y_target = DataLabeler.create_sequences(X, y)
        
        # 2. Ø¨Ø±Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ 2D
        sequence_length = X_seq.shape[1]
        X_flat_train = X.iloc[sequence_length : len(X)] 
        
        # --- Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ A (LSTM) ---
        num_features = X_seq.shape[2]
        self.predictor_A = LSTM_Predictor(sequence_length, num_features)
        print("ðŸ¤– [Ensemble] Training Model A (LSTM - Sequence)...")
        self.predictor_A.train(X_seq, y_target)
        
        # --- Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ B (Logistic) ---
        print("ðŸ¤– [Ensemble] Training Model B (Logistic Regression - Simple)...")
        self.predictor_B.fit(X_flat_train, y_target)
        
        # --- Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ú©Ù…Ú©ÛŒ (Auxiliary - SHAP) ---
        print("ðŸ¤– [Ensemble] Training Auxiliary Model (for SHAP)...")
        # Ø§Ù„Ø§Ù† MarketPredictor Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ùˆ Ø¨Ø§ Ø¢Ø±Ø§ÛŒÙ‡ Ù†Ø§Ù…Ù¾Ø§ÛŒ y_target Ù‡Ù… Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        self.aux_predictor.train(X_flat_train, y_target) 
        
        self.is_trained = True

    def predict_combined(self, X_sample: pd.DataFrame) -> tuple:
        """
        Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ù‡Ø§ÛŒÛŒ.
        X_sample: Ø¯Ù‚ÛŒÙ‚Ø§ 10 Ø±Ø¯ÛŒÙ Ø¢Ø®Ø± Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… (DataFrame)
        """
        if not self.is_trained:
            return 0, 0.5
            
        # --- FIX: ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø³ØªÛŒ Ø¨Ù‡ ÙØ±Ù…Øª 3D Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ---
        # Ø¨Ù‡ Ø¬Ø§ÛŒ create_sequences Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯ÛŒØªØ§ÛŒ Ø¨ÛŒØ´ØªØ± Ø¯Ø§Ø±Ø¯ØŒ
        # Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¯Ø§Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡ Ø´Ú©Ù„ (1, 10, Features) Ø¯Ø± Ù…ÛŒâ€ŒØ¢ÙˆØ±ÛŒÙ….
        
        X_values = X_sample.values # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ NumPy
        # Reshape: [Batch Size=1, Timesteps=10, Features=N]
        X_sample_seq_last = X_values.reshape(1, X_values.shape[0], X_values.shape[1])
        
        # 1. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ LSTM
        prob_A = self.predictor_A.model.predict(X_sample_seq_last, verbose=0)[0][0]
        
        # 2. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Logistic (ÙÙ‚Ø· Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„)
        X_flat_last = X_sample.iloc[-1].values.reshape(1, -1)
        prob_B = self.predictor_B.predict_proba(X_flat_last)[0][1]
        
        # 3. ØªØ±Ú©ÛŒØ¨ (70% LSTM, 30% Logistic)
        final_prob = (0.70 * prob_A) + (0.30 * prob_B)
        final_prediction = 1 if final_prob >= 0.5 else 0
        
        return final_prediction, final_prob